{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharma7056/renuinde577project/blob/main/SupervisedLearning/5%20-%20Neural%20Network/MLP_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqgbfx91A4-V"
      },
      "source": [
        "# Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11c2oXTSA4-X"
      },
      "source": [
        "In this notebook, implementats a multilayered perceptron with a single input layer with $784$ input nodes, 2 hidden layers of arbitrary size, and $10$ output nodes. These layers will be denoted $L^0, L^1, L^2,$ and $L^{3}$, respectively.\n",
        "\n",
        "<img src=\"https://github.com/sharma7056/renuinde577project/blob/main/SupervisedLearning/5%20-%20Neural%20Network/Image/MLP_2.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "For $l = 1, 2, 3$, layer $l$ will have two phases:\n",
        "\n",
        "* The preactivation phase $z^l = W^la^{l-1} + b^l,$\n",
        "* The postactivation phase $a^l = \\sigma(z^l).$\n",
        "\n",
        "The preactivation phase includes a weighted linear combination of postactivation values in the previous layer. The postactivation values includes passing the preactivation value through a chosen activation function elementwise. For notational convience, let $a^0 = x$, where $x$ is the current input data into our network. This notebook use sigmoid function as the activation function.\n",
        "\n",
        "* Sigmoid Function\n",
        "$$\n",
        "\\sigma(s) = \\frac{1}{1+e^{-s}}.\n",
        "$$\n",
        "\n",
        "For our cost function, Mean Squared Error is used:\n",
        "$$\n",
        "C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n(a^i - y^i)^2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUMDs3KA4-Y"
      },
      "source": [
        "### About the MNIST Data Set\n",
        "\n",
        "The MNIST data set consists of $70000$ images of hand written digits, $60000$ of which are typically used as labeled training examples, where the other $10000$ are used for testing your learning model on.\n",
        "\n",
        "<img src=\"https://github.com/sharma7056/renuinde577project/blob/main/SupervisedLearning/5%20-%20Neural%20Network/Image/mnist-3.0.1.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X8F9AqMA4-Y"
      },
      "source": [
        "Each image in the MNIST data set is stored as a matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfP4n4kkA4-Y"
      },
      "source": [
        "### Goal\n",
        "\n",
        "To classify handwritten digits using the Multilayer Perceptron Learning algorithm based on the [MNIST data](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "### Tools\n",
        "\n",
        "This notebook uses the following libraries:\n",
        "\n",
        "* [matplotlib](http://metplotlib.org)\n",
        "* [numpy](https://numpy.org/doc/stable/index.html)\n",
        "* [tensorflow](https://www.tensorflow.org/)\n",
        "\n",
        "To load the MNIST data, we also need to import [keras.dataset](https://keras.io/api/datasets/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y9uAkNhNk8rR"
      },
      "outputs": [],
      "source": [
        "# Import the necessaty libraries\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stLONDz_A4-a"
      },
      "source": [
        "### Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YjyCr3nA4-a",
        "outputId": "5072d6f7-c31b-4fc8-d9cd-42b554172441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLMr5GoLoXOX",
        "outputId": "36bafe6d-ea3a-4007-c4f8-41bb1e41446e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# shape of the training set\n",
        "train_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnmX7oVroqnB",
        "outputId": "8b5f63c8-c7fe-480c-fce2-63fe7223dbb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# shape of the first matrix in the training set\n",
        "train_X[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCz44XiPpQLx",
        "outputId": "9c503dc6-698a-4c8d-88da-6d6b9c862e2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# shape of the test set\n",
        "test_X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePXVR0LhA4-c"
      },
      "source": [
        "The training set has $60000$ pictures with $28 \\times 28$ pixel. The test set has $10000$ pictures with the same $28 \\times 28$ pixel.\n",
        "\n",
        "For a better understanding check the first data point in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "U500A41Goxyw",
        "outputId": "ae467e79-811d-4429-ad51-6c30730e6d30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d157b887310>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# first matrix in the training set\n",
        "plt.imshow(train_X[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Bn_HlOouLx",
        "outputId": "58651647-b826-4423-a0e5-e81ce6fc25f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# first label of the training set\n",
        "train_y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCna5zkaA4-c"
      },
      "source": [
        "The matrix and the label match.\n",
        "\n",
        "Examines, the range of the grey scale ($x$) in the training matrics. If the range is big, it may require scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNQ2bm7oo2mx",
        "outputId": "1e863a84-c301-4d7f-db00-a4833a4b1213"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.max(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scJEuiz0A4-d",
        "outputId": "7b10d6b0-0ec9-4fea-9640-fed2742f325a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.min(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iWnw9JzA4-d",
        "outputId": "fb15f6f7-58e2-49b0-a801-6a4c2940fe05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.max(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YskPigidA4-d",
        "outputId": "796a5a92-b5fd-4d4a-c70d-4566fa6140c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "np.min(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waoGVMVqA4-e"
      },
      "source": [
        "The the range of the grey scale ($x$) is $(0, 255)$, and thus, require scaling. To scale it down divide by the maximun value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3mAE2bI2o-BB"
      },
      "outputs": [],
      "source": [
        "# Scale down X\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zljt7MrA4-e"
      },
      "source": [
        "Then we need to reshape the input matrics ($X$) and output matrics ($y$) to a desire pattern that can fit our algorithm.\n",
        "\n",
        "First, for the input matrics ($X$), we need to flatten the $28 \\times 28$ matrix, and reshape it to a $784 \\times 1$ vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FW-IrQORpSLw"
      },
      "outputs": [],
      "source": [
        "# X will temp store flattened matrices\n",
        "X = []\n",
        "for x in train_X:\n",
        "  X.append(x.flatten().reshape(784, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FftqLlqRA4-f"
      },
      "source": [
        "Second, for the output matrics ($y$), it is a single number, and we need to do the One Hot Encoding and represent it using a $10 \\times 1$ vector. For example,\n",
        "\n",
        "$$y=5 \\overset{\\text {One Hot encode}}{\\rightarrow} y =\\begin{bmatrix}\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "1\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\\\\\n",
        "0\n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X7BxIFm8A4-f"
      },
      "outputs": [],
      "source": [
        "# Y will temp store one-hot encoded label vectors\n",
        "Y = []\n",
        "for y in train_y:\n",
        "  temp_vec = np.zeros((10, 1))\n",
        "  temp_vec[y][0] = 1.0\n",
        "  Y.append(temp_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yi7Zy32FA4-f"
      },
      "outputs": [],
      "source": [
        "# Our data will be stored as a list of tuples\n",
        "train_data = [p for p in zip(X, Y)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCa3KluOA4-f"
      },
      "source": [
        "So far, the \"train_data\" would have one column with the flattened $X$ vectors and the one column with the One Hot encoded label vectors. We can pick the first data point and print the One Hot encoded label and the original true value to check the transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90JMH_S57bih",
        "outputId": "58676c25-0978-4148-96da-ed78af5802c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "p = train_data[0]\n",
        "print(p[1])\n",
        "print(train_y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn4gMG6_A4-g"
      },
      "source": [
        "The transformation is correct! Repeat the same thing on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KcZIVltbp_vv"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "for x in test_X:\n",
        "  X.append(x.flatten().reshape(784, 1))\n",
        "\n",
        "Y = []\n",
        "for y in test_y:\n",
        "  temp_vec = np.zeros((10, 1))\n",
        "  temp_vec[y][0] = 1.0\n",
        "  Y.append(temp_vec)\n",
        "\n",
        "test_data = [p for p in zip(X, Y)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3heeBJwzA4-g"
      },
      "source": [
        "---\n",
        "#### Activation Function\n",
        "Use the sigmoid function as the activation function,\n",
        "$$\\sigma(z)=\\frac {1}{1+e^{-z}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uQ2RvMV5qJsu"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "  return sigmoid(z)*(1.0-sigmoid(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3CSZ2xRA4-g"
      },
      "source": [
        "#### Loss Function\n",
        "Use the Mean Sqaure Error cost:\n",
        "$$\n",
        "C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n(a^i - y^i)^2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JGa9ZA59A4-h"
      },
      "outputs": [],
      "source": [
        "def mse(a, y):\n",
        "  return .5*sum((a[i]-y[i])**2 for i in range(10))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sd2D-7oA4-h"
      },
      "source": [
        "#### The Function to Initialize the Weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c7iB08AIrCbc"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(layers = [784, 60, 60, 10]):\n",
        "  W = [[0.0]]  #add weight_0, to match the shape\n",
        "  B = [[0.0]]\n",
        "  for i in range(1, len(layers)):\n",
        "    w_temp = np.random.randn(layers[i], layers[i-1])*np.sqrt(2/layers[i-1])  #Scaling initializer to scale the shape\n",
        "    b_temp = np.random.randn(layers[i], 1)*np.sqrt(2/layers[i-1])\n",
        "\n",
        "    W.append(w_temp)\n",
        "    B.append(b_temp)\n",
        "  return W, B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o4RVAvCA4-h"
      },
      "source": [
        "Let's test!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2NrwX_wRrEx8"
      },
      "outputs": [],
      "source": [
        "W, B = initialize_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "m1Xn3ZXJrN57"
      },
      "outputs": [],
      "source": [
        "x, y = train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjHyL9mfA4-i"
      },
      "source": [
        "First layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "G1cBt3SotSqZ"
      },
      "outputs": [],
      "source": [
        "a0 = x\n",
        "z1 = (W[1] @ a0) + B[1]\n",
        "a1 = sigmoid(z1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dflUcRI-BpL",
        "outputId": "134776da-1f3c-4c33-ceb5-2e381e9ad84d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "a1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uyc22pUA4-i"
      },
      "source": [
        "The shape of the output of the first layer match the desire dimension.\n",
        "\n",
        "Second layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89DswyFrtiT5",
        "outputId": "bec25072-82ef-4000-afdd-0416dce72d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 1)\n"
          ]
        }
      ],
      "source": [
        "z2 = (W[2] @ a1) + B[2]\n",
        "a2 = sigmoid(z2)\n",
        "print(a2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxDpII1VA4-j"
      },
      "source": [
        "The shape of the output of the second layer match the desire dimension.\n",
        "\n",
        "And the third layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uB0Mk4otizq",
        "outputId": "51ee590d-5b85-440b-bae9-489fa2d922d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n"
          ]
        }
      ],
      "source": [
        "z3 = (W[3] @ a2) + B[3]\n",
        "a3 = sigmoid(z3)\n",
        "print(a3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVqB1i8-A4-j"
      },
      "source": [
        "The shape of the output of the thired layer match the desire dimension.\n",
        "\n",
        "These results suggest that the \"innitialize_weights\" function works well. And then, we can put the input and output of the layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HdrA_7UOt5DX"
      },
      "outputs": [],
      "source": [
        "W, B = initialize_weights(layers=[784, 60, 60, 10])\n",
        "x, y = train_data[0]\n",
        "Z = [[0.0]]\n",
        "A = [x]\n",
        "L = len(B)\n",
        "for i in range(1, L):\n",
        "  z = (W[i] @ A[i-1]) + B[i]\n",
        "  a = sigmoid(z)\n",
        "\n",
        "  Z.append(z)\n",
        "  A.append(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfDMce7gA4-k"
      },
      "source": [
        "To check whether the loop works well, we can print the shape of the output of the layer before the last layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb0DO1EhurnG",
        "outputId": "0a911ed3-3511-40eb-be32-ddd55929159e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "A[-1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvKxI1dKA4-k"
      },
      "source": [
        "The shape is correct! Let's move on!\n",
        "\n",
        "#### Output Error\n",
        "\n",
        "The output error is\n",
        "\n",
        "$$\\delta^{l-1}=\\triangledown_{a^{l-1}}C \\otimes \\sigma'(z^{l-1})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3jAcb248uswW"
      },
      "outputs": [],
      "source": [
        "# Measure the output error\n",
        "deltas = dict()\n",
        "delta_last = (A[-1] - y)*sigmoid_prime(Z[-1])\n",
        "deltas[L-1] = delta_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ7zYBAHBWDd",
        "outputId": "6ca16c1d-e8cf-494e-e95b-7b65eac8c951"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.14535701],\n",
              "       [ 0.14737826],\n",
              "       [ 0.08449969],\n",
              "       [ 0.06322291],\n",
              "       [ 0.1147144 ],\n",
              "       [-0.10523133],\n",
              "       [ 0.12496116],\n",
              "       [ 0.0369833 ],\n",
              "       [ 0.04050453],\n",
              "       [ 0.11406395]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "deltas[L-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_uCo8_6A4-l"
      },
      "source": [
        "#### Neuron Error\n",
        "\n",
        "According to the output error, for $l=L-2,...,1$, the neuron error is\n",
        "\n",
        "$$\\delta^{l}=\\left ( (w^{l+1})^T a^{l+1} \\right ) \\otimes \\sigma'(z^{l})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3M5rIEebvg90"
      },
      "outputs": [],
      "source": [
        "# calculate the neuron error\n",
        "for l in range(L-2, 0, -1):\n",
        "  deltas[l] = (W[l+1].T @ deltas[l+1])*sigmoid_prime(Z[l])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms6IMLOIvhqW",
        "outputId": "bd07e0b5-2178-4166-f29b-c08417827967"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "deltas[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_RhQbiJA4-m",
        "outputId": "f10ebb0e-199c-43b2-d2c3-ff94bfe39750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "deltas[2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyBoovhIA4-m",
        "outputId": "b9580b96-1f51-487a-e8cf-2dfc267754df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "deltas[3].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq4yPTs7A4-m"
      },
      "source": [
        "The dimensions of the outputs of the layers are all correctly, suggesting that the codes for the output error and the neuron error work correctly.\n",
        "\n",
        "The gradient descent will be used to optimize the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wDGqFoFQwTqE"
      },
      "outputs": [],
      "source": [
        "# Set the learning rate\n",
        "alpha = 0.04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HKCHpDeVwgtj"
      },
      "outputs": [],
      "source": [
        "# To update the weights and bias\n",
        "for i in range(1, 4):\n",
        "  W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
        "  B[i] = B[i] - alpha*deltas[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2THvR1NaA4-n"
      },
      "source": [
        "#### Feedforward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "K8mHDPhiwxC0"
      },
      "outputs": [],
      "source": [
        "def forward_pass(W, B, p, predict_vector = False):\n",
        "  Z =[[0.0]]\n",
        "  A = [p[0]]\n",
        "  L = len(W)\n",
        "  for i in range(1, L):\n",
        "    z = (W[i] @ A[i-1]) + B[i]\n",
        "    a = sigmoid(z)\n",
        "\n",
        "    Z.append(z)\n",
        "    A.append(a)\n",
        "\n",
        "  if predict_vector == True:\n",
        "    return A[-1]\n",
        "  else:\n",
        "    return Z, A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzgwlrGjA4-n"
      },
      "source": [
        "#### Store the Neuron Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cT86kfr6A4-n"
      },
      "outputs": [],
      "source": [
        "def deltas_dict(W, B, p):\n",
        "  Z, A = forward_pass(W, B, p)\n",
        "  L = len(W)\n",
        "  deltas = dict()\n",
        "  deltas[L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
        "  for l in range(L-2, 0, -1):\n",
        "    deltas[l] = (W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
        "\n",
        "  return A, deltas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEc936sVA4-o"
      },
      "source": [
        "#### Average of Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nayiEoIVyepQ"
      },
      "outputs": [],
      "source": [
        "def MSE(W, B, data):\n",
        "  c = 0.0\n",
        "  for p in data:\n",
        "    a = forward_pass(W, B, p, predict_vector=True)\n",
        "    c += mse(a, p[1])\n",
        "  return c/len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHSMbMijA4-o"
      },
      "source": [
        "---\n",
        "\n",
        "### Implement the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF7uMRvUzO3w",
        "outputId": "a192bbce-2511-4bfe-df25-2d63dd4f9ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.54842481114301\n"
          ]
        }
      ],
      "source": [
        "# Calculate the initial cost\n",
        "W, B = initialize_weights()\n",
        "print(f\"Initial Cost = {MSE(W, B, train_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "jioHLhRrzcow",
        "outputId": "500d17c3-53bb-4829-f219-874999317a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value = 7\n",
            "Actual Value = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show the performance\n",
        "i = np.random.randint(0, len(test_X))\n",
        "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector=True))\n",
        "print(f\"Predicted Value = {prediction}\")\n",
        "print(f\"Actual Value = {test_y[i]}\")\n",
        "plt.imshow(test_X[i], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8tlM9lvA4-p"
      },
      "source": [
        "The prediction is wrong.\n",
        "\n",
        "Next, train the model using Stochasitc Gradient Descent method.\n",
        "\n",
        "#### Stochasitc Gradient Descent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F-Ggl8gj0VW-"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(W, B, data, alpha = 0.04, epochs = 3):\n",
        "  L = len(W)\n",
        "  print(f\"Initial Cost = {MSE(W, B, data)}\")\n",
        "  for k in range(epochs):\n",
        "    for p in data:\n",
        "      A, deltas = deltas_dict(W, B, p)\n",
        "      for i in range(1, L):\n",
        "        W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
        "        B[i] = B[i] - alpha*deltas[i]\n",
        "    print(f\"{k} Cost = {MSE(W, B, data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1iRbNB1A4-p",
        "outputId": "74763d03-1696-4dd8-e527-b6ac0f9f5a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.54842481114301\n",
            "0 Cost = 0.07478222907947903\n",
            "1 Cost = 0.053794121641219446\n",
            "2 Cost = 0.0430767682125117\n"
          ]
        }
      ],
      "source": [
        "stochastic_gradient_descent(W, B, train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OR1hsLIA4-q"
      },
      "source": [
        "The costs of every epoch gradually decrease. The training process works well.\n",
        "\n",
        "One example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "bT68icm1A4-q",
        "outputId": "66b3f2cf-05de-4123-9ce0-1fb03ebdc39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value = 3\n",
            "Actual Value = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "i = np.random.randint(0, len(test_X))\n",
        "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector=True))\n",
        "print(f\"Predicted Value = {prediction}\")\n",
        "print(f\"Actual Value = {test_y[i]}\")\n",
        "plt.imshow(test_X[i], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVl4MpD2A4-q"
      },
      "source": [
        "The prediction matches the true label.\n",
        "\n",
        "Put all the functions together to make a class. Also, use **mini-batch gradient descent** to optimize the algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WCsZvETL0fk-"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron():\n",
        "\n",
        "  def __init__(self, layers = [784, 60, 60, 10]):\n",
        "    self.layers = layers\n",
        "    self.L = len(self.layers)\n",
        "    self.W =[[0.0]]\n",
        "    self.B = [[0.0]]\n",
        "    for i in range(1, self.L):\n",
        "      w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
        "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
        "\n",
        "      self.W.append(w_temp)\n",
        "      self.B.append(b_temp)\n",
        "\n",
        "  def reset_weights(self, layers = [784, 60, 60, 10]):\n",
        "    self.layers = layers\n",
        "    self.L = len(self.layers)\n",
        "    self.W = [[0.0]]\n",
        "    self.B = [[0.0]]\n",
        "    for i in range(1, self.L):\n",
        "      w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
        "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
        "\n",
        "      self.W.append(w_temp)\n",
        "      self.B.append(b_temp)\n",
        "\n",
        "\n",
        "  def forward_pass(self, p, predict_vector = False):\n",
        "    Z =[[0.0]]\n",
        "    A = [p[0]]\n",
        "    for i in range(1, self.L):\n",
        "      z = (self.W[i] @ A[i-1]) + self.B[i]\n",
        "      a = sigmoid(z)\n",
        "      Z.append(z)\n",
        "      A.append(a)\n",
        "\n",
        "    if predict_vector == True:\n",
        "      return A[-1]\n",
        "    else:\n",
        "      return Z, A\n",
        "\n",
        "  def MSE(self, data):\n",
        "    c = 0.0\n",
        "    for p in data:\n",
        "      a = self.forward_pass(p, predict_vector=True)\n",
        "      c += mse(a, p[1])\n",
        "    return c/len(data)\n",
        "\n",
        "  def deltas_dict(self, p):\n",
        "    Z, A = self.forward_pass(p)\n",
        "    deltas = dict()\n",
        "    deltas[self.L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
        "    for l in range(self.L-2, 0, -1):\n",
        "      deltas[l] = (self.W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
        "\n",
        "    return A, deltas\n",
        "\n",
        "  def stochastic_gradient_descent(self, data, alpha = 0.04, epochs = 3):\n",
        "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
        "    for k in range(epochs):\n",
        "      for p in data:\n",
        "        A, deltas = self.deltas_dict(p)\n",
        "        for i in range(1, self.L):\n",
        "          self.W[i] = self.W[i] - alpha*deltas[i]@A[i-1].T\n",
        "          self.B[i] = self.B[i] - alpha*deltas[i]\n",
        "    print(f\"{k} Cost = {self.MSE(data)}\")\n",
        "\n",
        "\n",
        "  def mini_batch_gradient_descent(self, data, batch_size = 15, alpha = 0.04, epochs = 3):\n",
        "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
        "    data_length = len(data)\n",
        "    for k in range(epochs):\n",
        "        for j in range(0, data_length-batch_size, batch_size):\n",
        "            delta_list = []\n",
        "            A_list = []\n",
        "            for p in data[j:j+batch_size]:\n",
        "                A, deltas = self.deltas_dict(p)\n",
        "                delta_list.append(deltas)\n",
        "                A_list.append(A)\n",
        "\n",
        "                for i in range(1, self.L):\n",
        "                    self.W[i] = self.W[i] - (alpha/batch_size)*sum(da[0][i]@da[1][i-1].T for da in zip(delta_list, A_list))\n",
        "                    self.B[i] = self.B[i] - (alpha/batch_size)*sum(deltas[i] for deltas in delta_list)\n",
        "    print(f\"{k} Cost = {self.MSE(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzb0pgstA4-q"
      },
      "source": [
        "Let's try our class!\n",
        "\n",
        "We can also setup 60 nodes for both hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JHxk-iGLHzEG"
      },
      "outputs": [],
      "source": [
        "net = MultilayerPerceptron(layers=[784, 60, 60, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdH4zqk9A4-r"
      },
      "source": [
        "To use the stochastic gradient descent strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wSPs133H_HT",
        "outputId": "eb3dcb95-a763-4936-e3c0-6ad2e2fa0f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.2323385718448203\n",
            "2 Cost = 0.042240101959140165\n"
          ]
        }
      ],
      "source": [
        "net.stochastic_gradient_descent(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh6NpXJwA4-s"
      },
      "source": [
        "To use the mini-batch gradient descent strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJVa0rfEIBXj",
        "outputId": "9e085ab3-f732-48b5-c108-d0d986835818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 0.042240101959140165\n",
            "2 Cost = 0.03151405386137952\n"
          ]
        }
      ],
      "source": [
        "net.mini_batch_gradient_descent(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06e44z-BA4-s"
      },
      "source": [
        "Between mini-batch gradient descent and stochastic gradient descent, mini-batch gradient descent has a smaller cost.\n",
        "\n",
        "However, the mini-batch gradient descent requires more resources and takes a longer time to compute."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "MLP_Good.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "677d7cb3073a0b8867375a4e72362c1c4e2840c39316c25dc6682a3b67a3dfcd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}